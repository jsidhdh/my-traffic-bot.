import requests
from bs4 import BeautifulSoup

â€# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ© ---
BLOG_ID = "7821854519823506376"
API_KEY = "http://27304067439-hntv8ncnde7a90ot5d9d8bjka4f93a7l.apps.googleusercontent.com"
â€# Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù„ÙŠ Ø£Ø±Ø³Ù„ØªÙ‡
PRODUCT_URL = "https://www.noon.com/uae-en/N46787424A/p/"

def scrape_and_post():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    print("ğŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù†ØªØ¬ Ù…Ù† Ù†ÙˆÙ†...")
    try:
        response = requests.get(PRODUCT_URL, headers=headers)
        soup = BeautifulSoup(response.content, 'html.parser')

â€        # Ø³Ø­Ø¨ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬
        title = soup.find('h1').text.strip() if soup.find('h1') else "Ù…Ù†ØªØ¬ Ù…Ù…ÙŠØ² Ù…Ù† Ù†ÙˆÙ†"
        
â€        # Ø³Ø­Ø¨ Ø§Ù„Ø³Ø¹Ø± (Ù†ÙˆÙ† ÙŠØºÙŠØ± Ø§Ù„ÙƒÙˆØ¯ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹ØŒ Ù‡Ø°Ø§ ÙƒÙˆØ¯ ØªÙ‚Ø±ÙŠØ¨ÙŠ)
        price_tag = soup.find('div', {'class': 'priceNow'})
        price = price_tag.text.strip() if price_tag else "Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„Ø³Ø¹Ø±"

        print(f"âœ… ØªÙ… Ø³Ø­Ø¨: {title}")

â€        # ØªØ¬Ù‡ÙŠØ² Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ (HTML)
        post_content = f"""
        <h2>{title}</h2>
        <p>Ø¹Ø±Ø¶ Ø­ØµØ±ÙŠ Ù…Ù† Ù†ÙˆÙ†!</p>
        <p><b>Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ:</b> {price}</p>
        <br>
        <a href="{PRODUCT_URL}" style="padding: 10px 20px; background-color: #feee00; color: #000; text-decoration: none; font-weight: bold; border-radius: 5px;">Ø§Ø¶ØºØ· Ù‡Ù†Ø§ Ù„Ù„Ø´Ø±Ø§Ø¡ Ù…Ø¨Ø§Ø´Ø±Ø©</a>
        <br><br>
        <p>ØªØ³ÙˆÙ‚ Ø§Ù„Ø¢Ù† Ø¹Ø¨Ø± Ø±Ø§Ø¨Ø·Ù†Ø§ Ù„Ø¯Ø¹Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰.</p>
        """

â€        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¥Ù„Ù‰ Ø¨Ù„ÙˆØ¬Ø±
        print("ğŸ“¤ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù†Ø´Ø± ÙÙŠ Ø¨Ù„ÙˆØ¬Ø±...")
        publish_url = f"https://www.googleapis.com/blogger/v3/blogs/{BLOG_ID}/posts/"
        data = {
            "kind": "blogger#post",
            "title": title,
            "content": post_content
        }
        
        r = requests.post(f"{publish_url}?key={API_KEY}", json=data)
        
        if r.status_code == 200:
            print("ğŸ‰ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ù…Ù†ØªØ¬ Ù†Ø²Ù„ ÙÙŠ Ù…Ø¯ÙˆÙ†ØªÙƒ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")
        else:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±. Ø®Ø·Ø£: {r.text}")

    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

if __name__ == "__main__":
    scrape_and_post()
